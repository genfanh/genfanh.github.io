[{"content":"1. 概述 k8s的事件（Event）是一种资源对象（Resource Object），用于记录集群内发生的情况，kubernetes各个组件会把运行时发生的各种事件上报给api-server，如调度器做了什么决定等。默认情况下只会显示最近（一小时内）发生的事件。 由于k8s事件是一种资源对象，因此事件都会被存储在etcd中，而为了避免磁盘空间被填满，所以回强制执行保留策略：在最后一次的事件发生后，删除1小时之前发生的事件。 因为k8s系统中Pod资源是最核心的资源，如Deployment、StatefulSet、ReplicaSet、DaemonSet、Job、CronJob等最终都会创建出Pod。所以k8s事件也是围绕Pod进行的，在Pod的生命周期内的关键步骤中都会产生事件消息。Event资源数据结构体定义在core资源组下，具体代码示例如下：\n代码路径：vendor/k8s.io/api/core/v1/types.go\ntype Event struct { metav1.TypeMeta metav1.ObjectMeta InvolvedObject ObjectReference Reason string Message string Source EventSource FirstTimestamp metav1.Time LastTimestamp metav1.Time Count int32 Type string EventTime metav1.MicroTime Series *EventSeries Action string Related *ObjectReference ReportingController string ReportingInstance string } Event资源数据结构体描述了当前时间段内发生了哪些关键性事件。事件有两种类型：Normal（正常事件）和Warning（警告事件）。代码示例如下：\nconst ( // Information only and will not cause any problems \tEventTypeNormal string = \u0026#34;Normal\u0026#34; // These events are to warn that something might go wrong \tEventTypeWarning string = \u0026#34;Warning\u0026#34; ) 2. 架构 \r图1 EventBroadcaster事件管理机制运行原理\r EventBroadcaster事件运行原理如图1所示，Actor可以看做k8s系统中任一组件，当组件发生关键性事务时，可通过EventRecorder记录该事件，事件管理机制可以分为以下几个部分：\n EventRcorder： 事件（Event）生产者，也可叫做事件记录器。k8s系统组件通过EventRecorder记录关键性事件。 EventBroadcaster： 事件（Event）消费者，也叫做事件广播器。EventBroadcaster消费EventRecorder产生的事件兵分发给其已经连接的broadcasterWatcher。分发机制分为非阻塞分发和阻塞分发。 broadcasterWatcher： 观察者（Wathcer）用于定义事件的处理方式，如上传事件带api-server。  2.1. EventRecorder EventRecorder主要通过Eventf方法进行事件的记录，接口代码如下所示：\n代码路径：vendor/k8s.io/client-go/tools/record/event.go\ntype EventRecorder interface { Event(...) Eventf(...) AnnotatedEventf(...) }  Event: 对刚发生的事件进行记录 Eventf: 与Event方法类似，只是使用fmt.Sprintf对信息进行格式化 AnnotatedEventf: 与Eventf类型，但是附在了注释（Annotation）字段 Eventf方法记录当前事件路径为，Event -\u0026gt; recorder.makeEvent -\u0026gt; recorder.Action。Action函数通过goroutine操作实现一部操作，主要把Event对象写入m.incoming Channel中，完成事件的生产流程。Action函数代码示例如下：  代码路径：vendor/k8s.io/apimachinery/pkg/watch/mux.go\nfunc (m *Broadcaster) Action(action EventType, obj runtime.Object) { m.incoming \u0026lt;- Event{action, obj} } 2.2. EventBroadcaster EventBroadcaster消费EventRecorder记录的事件并分发给目前所有已经连接到该Eventbroadcaster的broadcasterWatcher。EventBroadcaster通过NewBroadcaster函数进行实例化：\n代码路径：vendor/k8s.io/client-go/tools/record/event_broadcaster.go\nfunc newBroadcaster(sink EventSink, sleepDuration time.Duration, eventCache map[eventKey]*eventsv1.Event) EventBroadcaster { return \u0026amp;eventBroadcasterImpl{ Broadcaster: watch.NewBroadcaster(maxQueuedEvents, watch.DropIfChannelFull), eventCache: eventCache, sleepDuration: sleepDuration, sink: sink, } } 在实例化过程中，回通过watch.NewBroadcaster函数在内部启动一个goroutine（m.loop函数）对m.incoming进行监控，并将监控的事件通过m.distribute函数分发给所有已经连接的broadcasterWatcher。通过m.fullChannelBehaboir标志区分分发机制，若标志为DropIfChannelFull时为非阻塞分发，此时w.result缓冲区满时事件会丢失；反之，为阻塞分发，事件不会丢失。m.loop和m.distribute代码如下：\n代码路径：vendor/k8s.io/apimachinery/pkg/watch/mux.go\nfunc (m *Broadcaster) loop() { // Deliberately not catching crashes here. Yes, bring down the process if there\u0026#39;s a \t// bug in watch.Broadcaster. \tfor event := range m.incoming { if event.Type == internalRunFunctionMarker { event.Object.(functionFakeRuntimeObject)() continue } m.distribute(event) } m.closeAll() m.distributing.Done() } func (m *Broadcaster) distribute(event Event) { if m.fullChannelBehavior == DropIfChannelFull { for _, w := range m.watchers { select { case w.result \u0026lt;- event: case \u0026lt;-w.stopped: default: // Don\u0026#39;t block if the event can\u0026#39;t be queued. \t} } } else { for _, w := range m.watchers { select { case w.result \u0026lt;- event: case \u0026lt;-w.stopped: } } } } 2.3. broadcasterWatcher broadcasterWatcher是每个k8s系统组件自定义处理事件的方式，如上报事件到api-server。每个broadcasterWatcher拥有三种自定义处理事件的函数：\n StartLogging： 将事件写入日志中 StartRecordingToSink： 将事件上报至api-server并存储到etcd中 StartStructuredLogging： 将事件根据入参的等级写入日志中 这StartLogging、StartRecordingToSink以及StartStructuredLogging函数依赖于StartEventWatcher函数，该函数内置了一个goroutine，不断的监控EventBroadcaster来发现事件并调用相关函数对事件进行处理。 下面对StartRecordingToSink函数进行重点介绍，如kubelet组件中的broadcasterWatcher为例，组件将v1core.EventSinkImpl作为上报事件的自定义函数。  代码路径：cmd/kubelet/app/server.go\n// makeEventRecorder sets up kubeDeps.Recorder if it\u0026#39;s nil. It\u0026#39;s a no-op otherwise. func makeEventRecorder(kubeDeps *kubelet.Dependencies, nodeName types.NodeName) { ... eventBroadcaster.StartStructuredLogging(3) if kubeDeps.EventClient != nil { ... eventBroadcaster.StartRecordingToSink(\u0026amp;v1core.EventSinkImpl{Interface: kubeDeps.EventClient.Events(\u0026#34;\u0026#34;)}) } else { ... } } 上报事件有3种方法：Create、Update、Patch。以Create方法为例，Create -\u0026gt; e.Interface.CreateWithEventNamespace(event)，该方法上报通过RESTClient发送POST请求，将事件发送到api-server。代码示例如下：\n代码路径：vendor/k8s.io/client-go/kubernetes/typed/core/v1/event_expansion.go\nfunc (e *events) CreateWithEventNamespace(event *v1.Event) (*v1.Event, error) { ... result := \u0026amp;v1.Event{} err := e.client.Post(). NamespaceIfScoped(event.Namespace, len(event.Namespace) \u0026gt; 0). Resource(\u0026#34;events\u0026#34;). Body(event). Do(context.TODO()). Into(result) return result, err } 3. 参考文献  《Kubernetes源码剖析》 作者：郑东旭 k8s源码 版本:release-1.20 commit:9158049ccd96cea766756c2c6370b728472e2246  ","date":"2021-02-06T17:53:39+08:00","permalink":"https://genfanh.github.io/p/client-go-eventbroadcaster/","title":"client-go EventBroadcaster事件管理器简介"},{"content":"1. 概述 k8s其他组件如kubelet、controller manager、scheduler都是通过client-go的Informer机制与api-server进行通信。所以在阅读组件源代码时，需要先理解client-go的informer机制。\n2. Informer架构 \r图1 Infomer架构\r\n如图所示，Informer的中核心组件有Reflector、DeltaFIFO以及Indexer。下面对各个组件进行重点介绍：\n2.1. Reflector Reflector主要用作监控(Watch)Informer创建时指定的k8s资源（可以是内置资源或者CRD资源），当监控的资源发生变化时会触发相应的事件，如Added事件、Updated事件、Deleted事件（分别对应资源对象的添加、更新以及删除），并将该事件对应的资源对象存放到本地缓存DeltaFIFO中。 Reflector对象主要通过NewReflector函数进行实例化，查看函数入参可以知道，在Reflector对象实例化的时候需要传入一个ListerWatcher数据接口对象，该对象拥有List和Watch方法，用于获取和监控资源列表。Reflector对象通过Run函数驱动监控并处理监控事件，在Run函数中可以看到，Reflector主要重复运行ListAndWatch函数获取资源列表(List)并监控(Watch)资源。\n代码路径：client-go/tools/cache/reflector.go\nfunc NewReflector(lw ListerWatcher, expectedType interface{}, store Store, resyncPeriod time.Duration) *Reflector { return NewNamedReflector(naming.GetNameFromCallsite(internalPackages...), lw, expectedType, store, resyncPeriod) } // Run repeatedly uses the reflector\u0026#39;s ListAndWatch to fetch all the // objects and subsequent deltas. // Run will exit when stopCh is closed. func (r *Reflector) Run(stopCh \u0026lt;-chan struct{}) { ... wait.BackoffUntil(func() { if err := r.ListAndWatch(stopCh); err != nil { r.watchErrorHandler(r, err) } }, r.backoffManager, true, stopCh) ... } ListAndWatch函数实现主要分为两个部分：1、获取资源列表数据(List)；2、监控资源对象(Watch)\n2.1.1. 获取资源数据(List) ListAndWatch List流程如下图所示： \r图2 ListAndWatch List流程图\r\n pager.New 主要根据ListerWatcher的List函数生成 pager 对象，若ListerWacher对象支持，Pager对象在后续调用List函数时，会使用Chunk方式分块进行获取资源列表，反之若ListerWacher对象不支持则会在一次http request中获取所有资源对象。 pager.List 用于获取资源下所有对象的数据，如Pod对象所有数据。获取资源数据是根据options的ResourceVersion参数控制，ResourceVersion=0表示获取所有数据；ResourceVersion!=0表示根据资源版本号继续获取，类似于断点续传功能。通过ResouceVersion保证本地缓存中数据有Etcd中数据保持一致。 listMetaInterface.GetResourceVersion 用于获取资源版本号，ResourceVersion（资源版本号）十分重要，Watch操作可以根据ResourceVersion判断当前资源对象是否发生改变。 meta.ExtractList用于将资源对象数据转换为资源对象列表，即把runtime.Object转为[]runtime.Object。 r.syncWith 将资源对象列表中的资源对象和对应版本号存储至DeltaFIFO中，同时会替换已经存在的对象。 r.setLastSyncResourceVersion 会设置最新的资源版本号。  ListAndWatch List代码示例：\n代码路径：client-go/tools/cache/reflector.go\nfunc (r *Reflector) ListAndWatch(stopCh \u0026lt;-chan struct{}) error { ... var resourceVersion string options := metav1.ListOptions{ResourceVersion: r.relistResourceVersion()} if err := func() error { ... go func() { ... pager := pager.New(pager.SimplePageFunc(func(opts metav1.ListOptions) (runtime.Object, error) { return r.listerWatcher.List(opts) })) ... list, paginatedResult, err = pager.List(context.Background(), options) ... }() ... listMetaInterface, err := meta.ListAccessor(list) ... resourceVersion = listMetaInterface.GetResourceVersion() ... items, err := meta.ExtractList(list) ... if err := r.syncWith(items, resourceVersion); err != nil { return fmt.Errorf(\u0026#34;unable to sync list result: %v\u0026#34;, err) } ... r.setLastSyncResourceVersion(resourceVersion) ... }(); err != nil { return err } ... } 2.1.2. 监控资源对象(Watch) Watch（监控）操作通过HTTP协议与API-Server建立长连接，接收api-server发来的资源变更时间，实现的机制是使用HTTP协议的分块传输编码(Chunked Transfer Encoding)。 ListAndWatch Watch代码示例：\n代码路径：client-go/tools/cache/reflector.go\nfunc (r *Reflector) ListAndWatch(stopCh \u0026lt;-chan struct{}) error { ... for { ... timeoutSeconds := int64(minWatchTimeout.Seconds() * (rand.Float64() + 1.0)) options = metav1.ListOptions{ ResourceVersion: resourceVersion, TimeoutSeconds: \u0026amp;timeoutSeconds, AllowWatchBookmarks: true, } ... w, err := r.listerWatcher.Watch(options) ... if err := r.watchHandler(start, w, \u0026amp;resourceVersion, resyncerrc, stopCh); err != nil { ... return nil } } } r.watchHandler 用于处理资源变更的事件。当出发Added事件、Updated事件、Deleted事件时，将对应的资源对象更新到本地缓存DeltaFIFO中并更新ResourceVersion版本号。 r.watchHandler 代码示例：\n代码路径：client-go/tools/cache/reflector.go\nfunc (r *Reflector) watchHandler(start time.Time, w watch.Interface, resourceVersion *string, errc chan error, stopCh \u0026lt;-chan struct{}) error { eventCount := 0 // Stopping the watcher should be idempotent and if we return from this function there\u0026#39;s no way \t// we\u0026#39;re coming back in with the same watch interface. \tdefer w.Stop() loop: for { select { ... case event, ok := \u0026lt;-w.ResultChan(): ... switch event.Type { case watch.Added: err := r.store.Add(event.Object) ... case watch.Modified: err := r.store.Update(event.Object) ... case watch.Deleted: err := r.store.Delete(event.Object) ... case watch.Bookmark: // A `Bookmark` means watch has synced here, just update the resourceVersion \tdefault: utilruntime.HandleError(fmt.Errorf(\u0026#34;%s: unable to understand watch event %#v\u0026#34;, r.name, event)) } *resourceVersion = newResourceVersion r.setLastSyncResourceVersion(newResourceVersion) ... } } ... } 2.2. DeltaFIFO DeltaFIFO可以分开理解，FIFO是一个先进先出队列，它拥有队列操作的基本方法（如Add、Update、Delete、List、Pop、Close等），而Delte是一个资源对象存储，用于保存资源对象的操作类型（如Added操作类型、Updated操作类型、Deleted操作类型、Sync操作类型等）。DeltaFIFO的struct结构代码如下所示：\n代码路径：client-go/tools/cache/delta_fifo.go\ntype DeltaFIFO struct { ... items map[string]Deltas queue []string ... } type Delta struct { Type DeltaType Object interface{} } type Deltas []Delta DeltaFIFO会保留所有关于资源对象(obj)的操作类型，队列中会存在拥有不同操作类型的同一个资源对象，队列的消费者能够在处理该资源对象时能够了解该资源对象所发生的事情。DeltaFIFO作为一个先进先出的队列，有其数据的生产者和消费者，其中生产者是Reflector调用的Add方法，消费者是Controller（informer的Controller）调用的Pop方法。下面针对DeltaFIFO的核心功能：生产者方法、消费者方法以及Resync机制进行介绍。\n2.2.1. 生产者方法 DeltaFIFO队列中的资源对象在Added事件、Updated事件、Deleted事件中都调用了queueActionLocked函数，该函数主要根据操作类型把资源对象append到队列中，具体的代码执行流程如下：\n 通过f.KeyOf计算资源对象的Key 将actionType和资源对象构造成Delta，添加到items中，并通过dedupDeltas函数进行去重操作 更新构造后的Delta并通过f.cond.Broadcast通知所有消费者解除阻塞  queueActionLocked代码示例如下：\n代码路径：client-go/tools/cache/delta_fifo.go\nfunc (f *DeltaFIFO) queueActionLocked(actionType DeltaType, obj interface{}) error { id, err := f.KeyOf(obj) ... oldDeltas := f.items[id] newDeltas := append(oldDeltas, Delta{actionType, obj}) newDeltas = dedupDeltas(newDeltas) if len(newDeltas) \u0026gt; 0 { if _, exists := f.items[id]; !exists { f.queue = append(f.queue, id) } f.items[id] = newDeltas f.cond.Broadcast() } else { ... } return nil } 2.2.2. 消费者方法 Pop方法作为消费者方法使用，该方法从DeltaFIFO的头部去除最早进入队列中的资源对象数据。在调用Pop方法时须传入process函数，该函数用于接收并处理对象的回调方法。Pop方法代码如下：\n代码路径：client-go/tools/cache/delta_fifo.go\nfunc (f *DeltaFIFO) Pop(process PopProcessFunc) (interface{}, error) { f.lock.Lock() defer f.lock.Unlock() for { for len(f.queue) == 0 { ... if f.closed { return nil, ErrFIFOClosed } f.cond.Wait() } id := f.queue[0] f.queue = f.queue[1:] ... item, ok := f.items[id] ... delete(f.items, id) err := process(item) if e, ok := err.(ErrRequeue); ok { f.addIfNotPresent(id, item) err = e.Err } return item, err } } 当队列中没有数据时，通过f.cond.Wait阻塞等待数据，只有收到cond.Broadcast时才说明有数据加入队列，此时阻塞才被清除。如果队列不为空，则取出队列头，将该对象传入process函数，由上层消费者处理，若process回调函数处理出错，则将对象重新存入队列。 Controller的processLoop方法负责从DeltaFIFO队列中取出数据，并传给回调函数。而process回调函数代码示例如下：\n代码路径：client-go/tools/cache/shared_informer.go\nfunc (s *sharedIndexInformer) HandleDeltas(obj interface{}) error { ... for _, d := range obj.(Deltas) { switch d.Type { case Sync, Replaced, Added, Updated: ... if old, exists, err := s.indexer.Get(d.Object); err == nil \u0026amp;\u0026amp; exists { if err := s.indexer.Update(d.Object); err != nil { return err } ... s.processor.distribute(updateNotification{oldObj: old, newObj: d.Object}, isSync) } else { if err := s.indexer.Add(d.Object); err != nil { return err } s.processor.distribute(addNotification{newObj: d.Object}, false) } case Deleted: if err := s.indexer.Delete(d.Object); err != nil { return err } s.processor.distribute(deleteNotification{oldObj: d.Object}, false) } } return nil } HandleDeltas函数作为process回调函数，当资源对象的操作类型为Added、Updated、Deleted时，在indexer中对该资源对象进行相应操作（该操作并发安全），并通过distribute函数将资源对象分发至SharedInformer中。如Added操作即对应的informer.AddEventHandler函数。\n2.2.3. Resync机制 Resync机制会将Indexer本地存储中的资源对象同步到DeltaFIFO中，并将这些资源对象设置为Sync操作类型。Resync函数在Reflector中定时执行，执行周期在生成Reflector对象时，由传入的resyncPeriod参数设定。具体代码在ListAndWatch函数中，如下所示：\n代码路径：client-go/tools/cache/reflector.go\nfunc (r *Reflector) ListAndWatch(stopCh \u0026lt;-chan struct{}) error { ... resyncerrc := make(chan error, 1) cancelCh := make(chan struct{}) defer close(cancelCh) go func() { resyncCh, cleanup := r.resyncChan() ... for { select { case \u0026lt;-resyncCh: case \u0026lt;-stopCh: return case \u0026lt;-cancelCh: return } if r.ShouldResync == nil || r.ShouldResync() { ... if err := r.store.Resync(); err != nil { resyncerrc \u0026lt;- err return } } ... } }() ... } Reflector 在 ListAndWatch 函数中启动了一个goroutine定时实行r.store.Resync操作，而在DeltaFIFO中Resync-\u0026gt;syncKeyLocked代码如下：\n代码路径：client-go/tools/cache/delta_fifo.go\nfunc (f *DeltaFIFO) syncKeyLocked(key string) error { obj, exists, err := f.knownObjects.GetByKey(key) ... id, err := f.KeyOf(obj) ... if err := f.queueActionLocked(Sync, obj); err != nil { return fmt.Errorf(\u0026#34;couldn\u0026#39;t queue object: %v\u0026#34;, err) } return nil } f.knownObjects是indexer本地存储对象，通过该对象可以获取client-go目前存储的所有资源对象。\n2.3. Indexer Indexer是client-go用来存储资源对象并自带索引功能的本地存储，Reflector从DeltaFIFO中将消费出来的资源对象存储至Indexer。Indexer中的数据与Etcd中数据完全一致，因此client-go可以方便地从本地存储中获取数据，无需每次都从远端etcd获取，减轻api-server压力。 Indexer是在ThreadSafeMap（具有并发安全特性）的基础上进行了封装，除了继承了ThreadSafeMap的操作方法同时实现了Indexer Func等功能（如Index、IndexKyes、GetIndexers等方法），存储结构如下图所示： \rIndexer存储结构\r\n2.3.1. ThreadSafeMap并发安全存储 ThreadSafeMap是一个内存中的存储，数据不会写入本地磁盘中，在进行增、删、该、查操作都会进行加锁，以保证数据的一致性。ThreadSafeMap将资源对象存储于一个map数据结构中。其数据结构代码如下：\n代码路径：client-go/tools/cache/thread_safe_store.go\ntype threadSafeMap struct { lock sync.RWMutex items map[string]interface{} // indexers maps a name to an IndexFunc \tindexers Indexers // indices maps a name to an Index \tindices Indices } items字段存储的是资源对象数据，其中items的key通过keyFunc函数计算得到。\n2.3.2. Indexer索引器 每次增、删、改ThreadSafeStore数据时，都会通过updateIndeces或deleteFromIndeices函数变更Indexer。Indexer被设计为可以自定义索引函数，其4个非常重要的数据结构为Indeices、Index、Indexer以及IndexFunc，数据结构如下：\n代码路径：client-go/tools/cache/index.go\n// IndexFunc knows how to compute the set of indexed values for an object. type IndexFunc func(obj interface{}) ([]string, error) // Index maps the indexed value to a set of keys in the store that match on that value type Index map[string]sets.String // Indexers maps a name to a IndexFunc type Indexers map[string]IndexFunc // Indices maps a name to an Index type Indices map[string]Index  Indexers: 存储索引器，key为索引器名称，value为索引器实现函数。 IndexFunc: 索引器函数，定义为接受一个资源对象，返回索引结果列表。 Indices: 存储缓存器，key为缓存器名称，value为缓存数据。 Index: 存储缓存数据，数据结构为K/V结构。  2.3.3. Indexer索引器核心实现 index.ByIndex函数通过执行索引器函数得到索引结果，代码示例：\n代码路径：client-go/tools/cache/thread_safe_store.go\nfunc (c *threadSafeMap) ByIndex(indexName, indexedValue string) ([]interface{}, error) { ... indexFunc := c.indexers[indexName] ... index := c.indices[indexName] set := index[indexedValue] list := make([]interface{}, 0, set.Len()) for key := range set { list = append(list, c.items[key]) } return list, nil } ByIndex接收两个参数:IndexName(索引器名称)和indexKey(需要检索的key)。首先从c.indexers中查找指定的索引器函数，从c.indices中查找指定的缓存器函数，然后根据索引的indexKey从缓存数据中查到并返回\n3. 参考文献  《Kubernetes源码剖析》 作者：郑东旭 client-go源码 版本:release-1.20 commit:fb61a7c88cb9f599363919a34b7c54a605455ffc  ","date":"2021-02-03T20:38:01+08:00","permalink":"https://genfanh.github.io/p/client-go-informer/","title":"client-go Informer简介"},{"content":"一、题目 \r题目\r\n二、解法 方法1：并归排序+最小堆 解法\n由题目给出的性质可知，这个矩阵的每一行均为一个有序数组。问题即转化为从这 nn 个有序数组中找第 kk 大的数，可以想到利用归并排序的做法，归并到第 kk 个数即可停止。\n一般归并排序是两个数组归并，而本题是 nn 个数组归并，所以需要用小根堆维护，以优化时间复杂度。\n具体如何归并，可以参考23. 合并K个升序链表 - 力扣（LeetCode） (leetcode-cn.com)。\n代码\nfunc kthSmallest(matrix [][]int, k int) int { h := \u0026amp;IHeap{} // 按行把每行最小数入堆 \tfor i := 0; i \u0026lt; len(matrix); i++ { heap.Push(h, [3]int{matrix[i][0], i, 0}) } // 从 0 ~ k - 1， 先把最小数出堆，再把最小数所在行的下一个数入堆， \t// 循环 k - 1 次之后， 所有小于 第 k小 的数都不在堆中， 并且最小的第k个数就在堆顶 \tfor i := 0; i \u0026lt; k - 1; i++ { now := heap.Pop(h).([3]int) if now[2] != len(matrix) - 1 { heap.Push(h, [3]int{matrix[now[1]][now[2]+1], now[1], now[2]+1}) } } return heap.Pop(h).([3]int)[0] } type IHeap [][3]int func (h IHeap) Len() int { return len(h) } func (h IHeap) Less(i, j int) bool { return h[i][0] \u0026lt; h[j][0] } func (h IHeap) Swap(i, j int) { h[i], h[j] = h[j], h[i] } func (h *IHeap) Push(x interface{}) { *h = append(*h, x.([3]int)) } func (h *IHeap) Pop() interface{} { old := *h n := len(old) x := old[n-1] *h = old[0 : n-1] return x } 复杂度分析\n时间复杂度：$O(k\\log{n})$，归并 $k$ 次，每次堆中插入和弹出的操作时间复杂度均为 $\\log{n}$。\n空间复杂度：$O(n)$，堆的大小始终为 $n$。\n 需要注意的是，$k$ 在最坏情况下是 $n^2$，因此该解法最坏时间复杂度为 $O(n^2\\log{n})$。\n 方法2：二分查找 解法\n由题目给出的性质可知，这个矩阵内的元素是从左上到右下递增的（假设矩阵左上角为 $matrix[0][0]$）。以下图为例：\n\r\n我们知道整个二维数组中 $matrix[0][0]$ 为最小值，$matrix[n - 1][n - 1]$ 为最大值，现在我们将其分别记作 $l$ 和 $r$。\n可以发现一个性质：任取一个数 $mid$ 满足 $l\\leq mid \\leq r$，那么矩阵中不大于 $mid$ 的数，肯定全部分布在矩阵的左上角。\n例如下图，取 $mid=8$：\n\r\n我们可以看到，矩阵中大于 $mid$ 的数就和不大于 $mid$ 的数分别形成了两个板块，沿着一条锯齿线将这个矩形分开。其中左上角板块的大小即为矩阵中不大于 $mid$ 的数的数量。\n读者也可以自己取一些 $mid$ 值，通过画图以加深理解。\n我们只要沿着这条锯齿线走一遍即可计算出这两个板块的大小，也自然就统计出了这个矩阵中不大于 $mid$ 的数的个数了。\n走法演示如下，依然取 $mid=8$：\n\r\n可以这样描述走法：\n初始位置在 $matrix[n - 1][0]$（即左下角）；\n设当前位置为 $matrix[i][j]$。若 $matrix[i][j] \\leq mid$，则将当前所在列的不大于 $mid$ 的数的数量（即 $i + 1$）累加到答案中，并向右移动，否则向上移动；\n不断移动直到走出格子为止。\n我们发现这样的走法时间复杂度为 $O(n)$，即我们可以线性计算对于任意一个 $mid$，矩阵中有多少数不大于它。这满足了二分查找的性质。\n不妨假设答案为 $x$，那么可以知道 $l\\leq x\\leq r$，这样就确定了二分查找的上下界。\n每次对于「猜测」的答案 $mid$，计算矩阵中有多少数不大于 $mid$ ：\n如果数量不少于 $k$，那么说明最终答案 $x$ 不大于 $mid$； 如果数量少于 $k$，那么说明最终答案 $x$ 大于 $mid$。 这样我们就可以计算出最终的结果 $x$ 了。\n代码\nfunc kthSmallest(matrix [][]int, k int) int { n := len(matrix) left, right := matrix[0][0], matrix[n-1][n-1] for left \u0026lt; right { mid := left + (right - left) / 2 if check(matrix, mid, k, n) { right = mid } else { left = mid + 1 } } return left } func check(matrix [][]int, mid, k, n int) bool { i, j := n - 1, 0 num := 0 for i \u0026gt;= 0 \u0026amp;\u0026amp; j \u0026lt; n { if matrix[i][j] \u0026lt;= mid { num += i + 1 j++ } else { i-- } } return num \u0026gt;= k } 复杂度分析\n时间复杂度：$O(n\\log(r-l))$，二分查找进行次数为 $O(\\log(r-l))$，每次操作时间复杂度为 $O(n)$。\n空间复杂度：$O(1)$。\n三、参考 转载自：有序矩阵中第K小的元素 - 有序矩阵中第K小的元素 - 力扣（LeetCode） (leetcode-cn.com)\n","date":"2020-11-09T14:57:36+08:00","permalink":"https://genfanh.github.io/p/kth-smallest-in-order-matrix/","title":"378.有序矩阵中第K小的元素"},{"content":"一、题目 \r题目\r\n二、解法 方法：Fisher-Yates 洗牌算法\nFisher-Yates 洗牌算法跟暴力算法很像。在每次迭代中，生成一个范围在当前下标到数组末尾元素下标之间的随机整数。接下来，将当前元素和随机选出的下标所指的元素互相交换 - 这一步模拟了每次从 “帽子” 里面摸一个元素的过程，其中选取下标范围的依据在于每个被摸出的元素都不可能再被摸出来了。此外还有一个需要注意的细节，当前元素是可以和它本身互相交换的 - 否则生成最后的排列组合的概率就不对了。\ntype Solution struct { r *rand.Rand nums []int } func Constructor(nums []int) Solution { return Solution{ r : rand.New(rand.NewSource(time.Now().UnixNano())), nums: nums, } } /** Resets the array to its original configuration and return it. */ func (this *Solution) Reset() []int { return this.nums } /** Returns a random shuffling of the array. */ func (this *Solution) Shuffle() []int { size := len(this.nums) ans := make([]int, size) copy(ans, this.nums) for i:=size; i\u0026gt;1; i-- { index := rand.Intn(i) ans[index], ans[i-1] = ans[i-1], ans[index] } return ans } /** * Your Solution object will be instantiated and called as such: * obj := Constructor(nums); * param_1 := obj.Reset(); * param_2 := obj.Shuffle(); */ 复杂度分析\n  时间复杂度 ： O(n)\nFisher-Yates 洗牌算法时间复杂度是线性的，因为算法中生成随机序列，交换两个元素这两种操作都是常数时间复杂度的。\n  空间复杂度： O(n)\n因为要实现 重置 功能，原始数组必须得保存一份，因此空间复杂度并没有优化。\n  三、参考 转载自： 打乱数组 - 打乱数组 - 力扣（LeetCode） (leetcode-cn.com)\n","date":"2020-11-08T15:32:46+08:00","permalink":"https://genfanh.github.io/p/scramble-array/","title":"384.打乱数组"},{"content":"一、题目 \r题目\r\n二、解法 1、方法1：使用额外数组 算法\n我们可以用一个额外的数组来将每个元素放到正确的位置上，也就是原本数组里下标为 $i$ 的我们把它放到 $(i+k)\\% 数组长度$ 的位置。然后把新的数组拷贝到原数组中。\nfunc rotate(nums []int, k int) { size := len(nums) ans := make([]int, size) for i:=0; i\u0026lt;size; i++ { ans[(i+k) % size] = nums[i] } for i:=0; i\u0026lt;size; i++ { nums[i] = ans[i] } } 复杂度分析\n 时间复杂度： O(n) 。将数字放到新的数组中需要一遍遍历，另一边来把新数组的元素拷贝回原数组。 空间复杂度： O(n)。另一个数组需要原数组长度的空间。  2、方法2：使用环状替换 算法\n如果我们直接把每一个数字放到它最后的位置，但这样的后果是遗失原来的元素。因此，我们需要把被替换的数字保存在变量 temp 里面。然后，我们将被替换数字（temp）放到它正确的位置，并继续这个过程 n 次， n 是数组的长度。这是因为我们需要将数组里所有的元素都移动。但是，这种方法可能会有个问题，如果 $n\\%k==0$，其中 $k=k\\%n$（因为如果 k 大于 n，移动 k 次实际上相当于移动次$k\\%n$）。这种情况下，我们会发现在没有遍历所有数字的情况下回到出发数字。此时，我们应该从下一个数字开始再重复相同的过程。\n现在，我们看看上面方法的证明。假设，数组里我们有 n 个元素并且 k 是要求移动的次数。更进一步，假设 $n%k=0$ 。第一轮中，所有移动数字的下标 i 满足 $ i\\%k==0 $ 。这是因为我们每跳 k 步，我们只会到达相距为 k 个位置下标的数。每一轮，我们都会移动 $\\frac{n}{k}$ 个元素。下一轮中，我们会移动满足 $ i\\%k==1 $的位置的数。这样的轮次会一直持续到我们再次遇到 $i\\%k==1$的地方为止，此时 $i=k$。此时在正确位置上的数字共有 $k × \\frac{n}{k} = k$ 个。因此所有数字都在正确位置上。\n让我们看一下接下来的例子，以更好地说明这个过程：\nnums: [1, 2, 3, 4, 5, 6]\rk: 2\r\r\nfunc rotate(nums []int, k int) { size := len(nums) k = k % size count := 0 for start := 0; count \u0026lt; size; start++ { current := start prev := nums[start] for { next := (current + k) % size prev, nums[next] = nums[next], prev current = next count++ if start == current { break } } } } 复杂度分析\n 时间复杂度：O(n) 。只遍历了每个元素一次。 空间复杂度：O(1) 。使用了常数个额外空间。  3、方法3：使用反转 算法\n这个方法基于这个事实：当我们旋转数组 $k$ 次， $k\\%n$ 个尾部元素会被移动到头部，剩下的元素会被向后移动。\n在这个方法中，我们首先将所有元素反转。然后反转前 $k$ 个元素，再反转后面 $n−k$ 个元素，就能得到想要的结果。\n假设 $n=7$ 且 $k=3$ 。\n原始数组 : 1 2 3 4 5 6 7\r反转所有数字后 : 7 6 5 4 3 2 1\r反转前 k 个数字后 : 5 6 7 4 3 2 1\r反转后 n-k 个数字后 : 5 6 7 1 2 3 4 --\u0026gt; 结果\rfunc rotate(nums []int, k int) { size := len(nums) k %= size r := func(ns []int, start, end int) { for start \u0026lt; end { nums[start], nums[end] = nums[end], nums[start] start++ end-- } } r(nums, 0, size-1) r(nums, 0, k-1) r(nums, k , size-1) } 复杂度分析\n 时间复杂度：O(n) 。 n 个元素被反转了总共 3 次。 空间复杂度：O(1) 。 没有使用额外的空间。  三、参考 转载自：旋转数组 - 旋转数组 - 力扣（LeetCode） (leetcode-cn.com)\n","date":"2020-11-08T14:24:44+08:00","permalink":"https://genfanh.github.io/p/rotate-array/","title":"189.旋转数组"},{"content":"一、题目 \r题目\r\n二、解法 动态规划 \r\n  初始化 dp=[false, ⋯ , false]，长度为 n+1。n 为字符串长度。dp[i] 表示 s 的前 i 位是否可以用 wordDict 中的单词表示。\n  初始化 dp[0]=true，空字符可以被表示。\n  遍历字符串的所有子串，遍历开始索引 i，遍历区间 [0,n)：\n 遍历结束索引 j，遍历区间 [i+1,n+1)：  若 dp[i]=true且 s[i, ⋯ ,j) 在 wordlist 中：dp[j]=true。解释：dp[i]=true 说明 s 的前 i 位可以用 wordDict 表示，则 s[i, ⋯ ,j) 出现在 wordDict 中，说明 s 的前 j 位可以表示。      返回 dp[n]\n  复杂度分析  时间复杂度：O(n^2^) 空间复杂度：O(n)  三、代码 func wordBreak(s string, wordDict []string) bool { size := len(s) m := make(map[string]bool, len(wordDict)) for _, word := range wordDict { m[word] = true } dp := make([]bool, size+1) dp[0] = true for i:=0; i\u0026lt;size; i++ { for j:=i+1; j\u0026lt;=size; j++ { if dp[i] \u0026amp;\u0026amp; m[s[i:j]] { dp[j] = true } } } return dp[size] } 四、参考 转载自：动态规划+记忆化回溯 逐行解释 python3 - 单词拆分 - 力扣（LeetCode） (leetcode-cn.com)\n","date":"2020-11-07T16:03:54+08:00","permalink":"https://genfanh.github.io/p/words-split/","title":"139.单词拆分"},{"content":"一、题目 \r题目\r\n二、解法 动态规划+回溯  动态规划得到了原始输入字符串的任意长度的 前缀子串 是否可以拆分为单词集合中的单词； 我们以示例 2：s = \u0026quot;pineapplepenapple\u0026quot;、wordDict = [\u0026quot;apple\u0026quot;, \u0026quot;pen\u0026quot;, \u0026quot;applepen\u0026quot;, \u0026quot;pine\u0026quot;, \u0026quot;pineapple\u0026quot;] 为例，分析如何得到所有具体解。  所有任意长度的前缀是否可拆分是知道的，那么如果 后缀子串在单词集合中，这个后缀子串就是解的一部分，例如：\n\r示例\r\n再对比这个问题的输出：\n[\r\u0026quot;pine apple pen apple\u0026quot;,\r\u0026quot;pineapple pen apple\u0026quot;,\r\u0026quot;pine applepen apple\u0026quot;\r]\r可以发现，树形结构中，从叶子结点到根结点的路径是符合要求的一个解，与以前做过的回溯算法的问题不一样，这个时候路径变量我们需要在依次在列表的开始位置插入元素，可以使用队列实现。\n三、代码 func wordBreak(s string, wordDict []string) bool { ans := make([]string, 0) size := len(s) // 使用 map 加速查找 \twordMap := make(map[string]bool, size + 1) for _, word := range wordDict { wordMap[word] = true } // 查找是否有解 \tdp := make([]bool, size+1) dp[0] = true for i:=0; i\u0026lt;size; i++ { for j:=i+1; j\u0026lt;=size; j++ { if dp[i] \u0026amp;\u0026amp; wordMap[s[i:j]] { dp[j] = true } } } // 回溯算法，获取所有解 \tpath := make([]string, 0) var backtracking func(start int) backtracking = func(start int) { if start == size \u0026amp;\u0026amp; dp[size] { tmp := strings.Join(path, \u0026#34; \u0026#34;) ans = append(ans, tmp) return } for i := start+1; i\u0026lt;=size; i++ { if dp[start] \u0026amp;\u0026amp; wordMap[s[start:i]] { path = append(path, s[start:i]) backtracking(i) path = path[:len(path)-1] } } } if dp[size] { backtracking(0) } return ans } 四、参考 转载自：动态规划求是否有解、回溯算法求所有具体解（Java） - 单词拆分 II - 力扣（LeetCode） (leetcode-cn.com)\n","date":"2020-11-07T16:03:54+08:00","permalink":"https://genfanh.github.io/p/words-split-ii/","title":"140.单词拆分II"},{"content":"一、题目 \r题目\r\n二、解法 回溯+动态规划优化 搜索问题主要使用回溯法。\n回溯法思考的步骤：\n1、画递归树；\n2、根据自己画的递归树编码。\n思考如何根据这棵递归树编码：\n1、每一个结点表示剩余没有扫描到的字符串，产生分支是截取了剩余字符串的前缀；\n2、产生前缀字符串的时候，判断前缀字符串是否是回文。\n如果前缀字符串是回文，则可以产生分支和结点； 如果前缀字符串不是回文，则不产生分支和结点，这一步是剪枝操作。 3、在叶子结点是空字符串的时候结算，此时从根结点到叶子结点的路径，就是结果集里的一个结果，使用深度优先遍历，记录下所有可能的结果。\n 采用一个路径变量 path 搜索，path 全局使用一个（注意结算的时候，需要生成一个拷贝），因此在递归执行方法结束以后需要回溯，即将递归之前添加进来的元素拿出去； path 的操作只在列表的末端，因此合适的数据结构是栈。  利用「力扣」第 5 题：最长回文子串 的思路，使用空间换时间，利用动态规划把结果先算出来，这样就可以以 O(1) 的时间复杂度直接得到一个子串是否是回文。\n三、代码 func partition(s string) [][]string { ans := make([][]string,0) size := len(s) if size == 0 { return ans } // 预处理 \t// 使用 dp[i][j] 表示 s[i:j] 是否回文 \tdp := make([][]bool, size) for i := range dp { dp[i] = make([]bool, size) } for r:=0; r\u0026lt;size; r++ { for l:=0; l\u0026lt;=r; l++ { if s[l] == s[r] \u0026amp;\u0026amp; (r - l \u0026lt;=2 || dp[l+1][r-1]) { dp[l][r] = true } } } path := make([]string, 0) var backtracking func(start int) backtracking = func (start int) { if start \u0026gt;= size { tmp := make([]string, len(path)) copy(tmp, path) ans = append(ans, tmp) return } for i := start; i \u0026lt; size; i++ { if !dp[start][i] { continue } path = append(path, s[start:i+1]) backtracking(i+1) path = path[:len(path)-1] } } backtracking(0) return ans } 四、参考 转载自：回溯、优化（使用动态规划预处理数组） - 分割回文串 - 力扣（LeetCode） (leetcode-cn.com)\n","date":"2020-11-07T15:15:03+08:00","permalink":"https://genfanh.github.io/p/split-palindrome-string/","title":"131.分割回文串"},{"content":"一、题目 \r题目\r\n二、解法 动态规划 dp[i][j]代表 word1 的前 i 个字符转换成 word2 的前 j 字符需要的最少操作数\n所以，\n当 word1[i] == word2[j] 时， dp[i][j] = dp[i-1][j-1]\n当 word1[i] != word2[j] 时， dp[i][j] = min(dp[i-1][j-1], dp[i-1][j], dp[i][j-1]) + 1\n其中，dp[i-1][j-1] 表示替换操作， dp[i-1][j] 表示删除操作， dp[i][j-1] 表示插入操作。\n注意，针对第一行和第一列需要淡入考虑，如下图所示，引入 '':\n\r\n第一行，是 word1 为空时变为 word2 最少要走的步数，也就是插入操作\n第一列，是 word2 为空时 word1 变为 word2 最少要走的步数， 也是删除操作\n最终结果就是 dp[i][j]\n复杂度 时间复杂度： O(m*n)\n空间复杂度： O(m*n)\n三、代码 func minDistance(word1 string, word2 string) int { n, m := len(word1), len(word2) dp := make([][]int, n+1) // word2 为空时 word1 变为 word2 最少要走的步数  for i:=0; i\u0026lt;=n; i++ { dp[i] = make([]int, m+1) dp[i][0] = i } // word1 为空时变为 word2 最少要走的步数  for j:=0; j\u0026lt;=m; j++ { dp[0][j] = j } for i:=1; i\u0026lt;=n; i++ { for j:=1; j\u0026lt;=m;j++ { if word1[i-1] == word2[j-1] { dp[i][j] = dp[i-1][j-1] } else { dp[i][j] = 1 + min(dp[i-1][j], min(dp[i][j-1], dp[i-1][j-1])) } } } return dp[n][m] } func min(x, y int) int { if x \u0026lt; y { return x } return y } ","date":"2020-11-05T17:51:36+08:00","permalink":"https://genfanh.github.io/p/edit-distance/","title":"72.编辑距离"},{"content":"一、题目 \r题目\r\n二、解法 动态规划 构造动态方程时，我们认为\n dp[i]为凑成i金额所需要的最少硬币的数值  所以，当所有coins面值硬币选择一个时，其凑成的dp[i-coins[j]]的数值是最小时，可以认为dp[i]最小，动态转化表达式可以有\ndp[i] = min( dp[i-coins[j]] ) + 1\r此时最终题解为，\n ans = dp[amount]  复杂度 时间复杂度：O(amount * len(coins) )\n空间复杂度：O(amount)\n三、代码 func coinChange(coins []int, amount int) int { if amount == 0 { return 0 } dp := make([]int, amount+1) // 初始化所有 i\u0026gt;0 的 dp[i] 为 -1  for i := range dp { if i != 0 { dp[i] = -1 } } n := len(coins) for i:=1; i\u0026lt;=amount; i++ { minVal := math.MaxInt64 for j:=0; j\u0026lt;n; j++ { // 若 dp[i-coins[j]] = -1 认为 dp[i-coins[j]] 无解  if i - coins[j] \u0026gt;= 0 \u0026amp;\u0026amp; dp[i-coins[j]] != -1 { minVal = min(minVal, dp[i-coins[j]]) } } // 若minVal没有被赋值， 则认为 dp[i] 无解  if minVal != math.MaxInt64 { dp[i] = minVal + 1 } } return dp[amount] } func min(x, y int) int { if x \u0026lt; y { return x } return y } ","date":"2020-11-05T17:10:50+08:00","permalink":"https://genfanh.github.io/p/coin-change/","title":"322.零钱兑换"},{"content":"一、题目 \r题目\r\n二、解法 动态规划 \r状态流转图\r\n交易k次的状态流转图如上图所示。\n初始状态时，手中没有股票，在初始状态可以保持该动作，不买不卖直至交易结束。\n初始状态只能通过买入进入到买入1状态，当买入1股后，我们可以有以下两种选择：\n 啥也不做，保持买入1股状态，直至若干天后择优卖出 马上手上股票，进入卖出1状态  在卖出1状态时，也有两种选择：\n 啥也不做，保持手上没有股票动作，直至下一个好时机买入 马上进行第二次买入，进入买入2状态  后面的买入2，保持，卖出2直至卖出k后，就无法在进行交易，只能进入交易结束状态\n所以在构造动态规划方程时，使用三个状态变量来表示买卖k次的交易状态\n i表示第i天 k表示已经进行了k次买卖 j表示当前手上是否持有股票  此时我们得到动态规划状态表达式dp[i][k][j]，其中\n dp[i][k][0]表示第i天交易了k次后手上不持有股票的累计最大利润 dp[i][k][1]表示第i天交易了k次后手上持有股票的累计最大利润  此时，我们通过状态转化图，可以有\n# 第i天交易k次后手上不持有股票的累计最大利润为， 1、第i-1天k次后手上不持有股票的累计最大利润，或 2、第i-1天k次交易后手上持有股票的累计最大利润加上第i天卖出股票 ； 1或2中的最大值\rdp[i][k][0] = max( dp[i-1][k][0], d[i-1][k][1] + prices[i] )\r# 第i天交易k次后手上持有股票的累计最大利润为， 1、第i-1天k次后手上持有股票的累计最大利润，或 2、第i-1天k-1次交易后手上不持有股票的累计最大利润减去第i天买入股票 ； 1或2中的最大值\rdp[i][k][1] = max( dp[i-1][k][1], dp[i-1][k-1][0] - prices[i])\r# 此时题目解为 第i天 0~k 次交易后，手上不持有股票的累计利润最大值\ranswer = max(dp[i][0~k][0])\r三、代码 func maxProfit(k int, prices []int) int { pLen := len(prices) if len(prices) == 0{ return 0 } //一次交易需要2天，如果交易次数大于总的天数/2，那么可以认为k是无穷大，套框架  if k \u0026gt; pLen/2{ return maxProfit_k_Inf(prices) } tmp := make([][2]int, k+1) dp := make([][][2]int, 0) for i:=0; i\u0026lt;pLen;i++{ dp = append(dp, tmp) } for i:=0; i\u0026lt;pLen; i++{ //base case  if i == 0 { for d:=0; d\u0026lt;=k; d++{ dp[i][d][0]=0 dp[i][d][1]=-prices[i] } continue } for j:=k; j\u0026gt;=1; j--{ dp[i][j][0]=max(dp[i-1][j][0], dp[i-1][j][1]+prices[i]) dp[i][j][1]=max(dp[i-1][j][1], dp[i-1][j-1][0]-prices[i]) } } return dp[pLen-1][k][0] } func maxProfit_k_Inf(prices []int) int { if len(prices) == 0 { return 0 } dp := make([][2]int, len(prices)) /* k = +infinity dp[i][k][0]=max(dp[i-1][k][0], dp[i-1][k][1]+prices[i]) dp[i][k][1]=max(dp[i-1][k][1], dp[i-1][k-1][0]-prices[i]) =max(dp[i-1][k][1], dp[i-1][k][0]-prices[i]) 我们发现数组中的 k 已经不会改变了，也就是说不需要记录 k 这个状态了： dp[i][0] = max(dp[i-1][0], dp[i-1][1] + prices[i]) dp[i][1] = max(dp[i-1][1], dp[i-1][0] - prices[i]) */ for i:=0; i\u0026lt;len(prices); i++{ if i-1 == -1{ dp[i][0]=0 dp[i][1]=-prices[i] continue } dp[i][0] = max(dp[i-1][0], dp[i-1][1] + prices[i]) dp[i][1] = max(dp[i-1][1], dp[i-1][0] - prices[i]) } return dp[len(prices)-1][0] } func max(x, y int) int{ if x \u0026gt; y{ return x } return y } ","date":"2020-11-04T20:30:57+08:00","permalink":"https://genfanh.github.io/p/sell-stock/","title":"188.买卖股票的最佳时机"},{"content":"今天主要记录用hugo搭建个人博客的过程，避免下次搭建流程遗失。\n一、安装Hugo 本人使用的是Windows系统，所以选择scoop安装方式。具体步骤如下：\n1、安装scoop 参考 github scoop 网站安装\n2、使用scoop安装hugo 安装hugo拓展版本，因为后续选择主题需要拓展版本，所以安装了此版本\nscoop install hugo-extended\r若不喜欢使用拓展版本，可以使用以下指令安装基础版本\nscoop install hugo\r3、验证hugo安装 打开CMD，输入hugo version，若版本正确输出则安装成功\n其他平台可参考官网安装教程 Install Hugo\n二、使用hugo创建博客 1、创建网站 在创建前，请进入工作目录\n# 执行创建指令\r# 其中 blog 是网站名称，即会在工作目录下创建blog名称文件夹\r# 所有网站文件都在blog目录下\rhugo new site blog\r2、添加hugo主题 hugo有很多第三方开源的主题，可以在官网的themes下自行选择。本人选Stack主题作为博客的主题。\n主题选好后进入blog（也就是刚才创建网站是创建出来的目录）目录下，把stack主题git到themes目录下。\ncd blog\rgit init\rgit submodule add https://github.com/CaiJimmy/hugo-theme-stack.git\r 注：记得提前安装git\n 3、修改config.toml配置文件 正常流程应该直接修改config.toml文件，但是Stack主题已经内置修改好的文件，直接复制该config.toml到根目录即可\necho 'theme = \u0026quot;hugo-theme-stack\u0026quot;' \u0026gt;\u0026gt; config.toml\r4、创建第一篇文章 hugo new posts/HelloWorld.md\r5、启动hugo服务器 hugo server -D\r三、把Hugo部署到Github Pages上 1、创建一个Github仓库 在github上创建一个仓库，名称一般为\u0026lt;gihub名称\u0026gt;.github.io\n\rgit_create_repo\r\n2、把仓库clone到本地 git clone \u0026lt;REPO_URL\u0026gt;\r3、创建hugo项目 参照第二步，在仓库目录下创建一个Hugo项目，同时保证hugo项目能在本地运行\nhugo server -D\r4、创建新文章 hugo new post/HelloWorld.md\r通过指令创建的markdown文章会自动生成如下模板头：\n--- title: \u0026#34;HelloWorld\u0026#34; date: 2020-10-30T21:52:31+08:00 draft: true ---  注：需要把 draft: true 改为 draft: false 才可以上传该篇文章\n 5、修改repo配置 进入刚刚创建的 Repository 的 Setting 界面， 把 GitHub Page 配置下的 Source 配置为Branch:master/docs。这意味着通过URL访问博客时，会从该仓库 master 分支下的 docs 文件夹下读取静态资源。具体如下图所示：\n\rrepo_settings\r\n6、修改 config.toml 从第5点得到 GitHub Page 的 URL，把该 URL 替换到 config.toml 配置文件的 baseURL 配置值中\nbaseURL = \u0026quot;https://genfanh.github.io/\u0026quot;\r7、打包网站到 /docs 文件夹下 hugo -d docs\r8、把项目 push 到 github 仓库下 git commit -m \u0026quot;上传hugo\u0026quot;\rgit push origin master\r9、查看成果 登录https://genfanh.github.io/查看是否部署成功\n\rresult\r\n四、参考资料 使用 Hugo + Github 搭建个人博客 - 知乎 (zhihu.com)\nInstall Hugo | Hugo\n","date":"2020-11-02T15:51:01+08:00","permalink":"https://genfanh.github.io/p/create-hugo-tutorial/","title":"使用 Hugo + Github Page 搭建个人博客"}]